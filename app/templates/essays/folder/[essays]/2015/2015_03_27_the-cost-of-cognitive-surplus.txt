Title: The Cost of Cognitive Surplus
Permalink: the cost of cognitive surplus
Date: March 27 2015
Tags: advertising, publishing

The Cost of Cognitive Surplus
====================

<p2>Picture me back in the habit. I took a break last week. It was needed. But I'm back with a bunch of words (prepare yourselves! prepare your hearts!), and am grateful you're willing to spend some of your cognitive surplus reading them. Speaking of which&hellip;</p2>

<p2>— CB, March 27, 2015</p2>

<p style="text-align:center;">ϟ</p>

**Back in 2010, we were all very excited about a new idea called "cognitive surplus."** As popularized by Clay Shirky in his book of the same name, the basic idea was that technology &mdash; especially *connective* technology like the internet &mdash; has enabled us to spend more of our time creating things and less of it consuming them. Huh. It's only been a few years, and yet it certainly doesn't take much subjective analysis to start doubting that idea.

That creative and *productively* creative pursuits are much more within reach today is inarguable. That we, in the aggregate, spend more of our time, per capita, on such things &mdash; even, as Shirky points out, if they are as trivial as a LOLcat &mdash; is also pretty darn clear. But creativity v. consumption is a false dichotomy, isn't it? Just say the words themselves a few times over, or imagine yourself being one or the other &mdash; creator or consumer. Sure, there are the obvious and theoretically opposite things you *could* imagine. You could imagine yourself, say, sculpting at a potter's wheel, your hands warm and wet against a smooth and spinning slab of clay, your senses alive, feeling, smelling, listening to the stone beneath you turn. Or, you could imagine yourself sitting on the couch, watching television, your hand clasped around the remote control, your mind transported to someplace else, the rest of your senses pretty much turned off, forgetting to feel much of anything. And when you think about it this way, *wow, what a difference*! But I'm not exactly giving you a fair comparison, am I? They're so clearly opposite, especially when described this way. Of course, if we wanted to be pedantic, we could examine all kinds of consumption that make a creative act like pottery possible &mdash; Did you *dig* the clay from the creek bed in your back yard, and did you *carve* the stone, and did you *forge* the metal that joins the wheel to the pedal? No, you bought it all at Utrecht. &mdash; just as we could deconstruct any act of consumption and see all the forms of creativity that came, necessarily, before it.

Really, most forms of creativity, especially in Shirky's treatment of the subject, are far less "classic" than what we just imagined. They're the smaller, more distributed acts of creativity unleashed by the keyboard, mouse, and screen. The 140-character missive, dashed off with thumbs. The direct to web phone pic. The sort of thing that made Tumblr something you know about today. And sadly, when the idea of cognitive surplus gets fleshed out in *that* way, it sounds a whole lot less remarkable, doesn't it? Or, perhaps more fairly put, that the theoretical chasm between creativity and consumption gets narrowed to the point of being barely more than a shade of difference. Perhaps in effect, perhaps in intent. Either way, entirely mundane. I wonder, then, does it make more sense to think of cognitive surplus simply as the growing opportunity to choose what one does with one's time thanks to the paradigm-shifting, job-sucking power of automation and technology? (See, you can't even talk about this without talking about the *other* side of the coin, on which it is far more plain that this clever turn of phrase bears relevance in some of the more privileged lives lived on this planet, but surely not all, nor most, but that is another rant entirely&hellip;) Back to the redefinition: That cognitive surplus is just the extra time that some of us have to do *whatever* because our dishwashers and roombas and computers are doing all kinds of busy work that we would otherwise have to do ourselves before collapsing in exhaustion only to do it all again the next day, leaving no time to plumb the depths of Instagram or binge-watch *House of Cards*. That the surplus is *time*, and what we tend to spend it on is the creation and consumption of information; of cognitive matter. The <a href="http://media.giphy.com/media/frKdMu98qkxKo/giphy.gif" target="_blank">GIF of the pot being thrown</a>, rather than, say, the pot itself. I mean, come on, which thing can you do from your couch?

As it turns out, statistics on media consumption &mdash; which we must cobble together from a variety of sources now that "media" no longer just means the stuff broadcast over the air or cable &mdash; <a href="http://www.statista.com/statistics/270781/average-daily-media-use-in-the-us/" target="_blank">indicate</a> that we're doing a lot of good, old-fashioned, couch-based consuming. Between 4-6 hours of television per day. 2-3 hours on the internet. About the same on a tablet. A bit less on a smartphone. 1-2 hours listening to the radio. Maybe a combined hour reading newspapers and magazines. That's a lot of time, and a lot of intake. Yes, the internet time, the tablet time, and the smartphone time *could* all be spent creatively, but surely some, if not *much*, of it is spent passively thumbing through feeds of things we look at, LOL, and forget. Not that there's anything wrong with that. But is it Shirky's cognitive surplus? Eh. *I* don't think so. But that is, admittedly, a subjective opinion, and I suspect that any thoughtful parsing-out of the creation/consumption dynamic of modern media is going to rely heavily on subjective opinion. I might go as far as to say that it is the very tangledness of it all that is creating the media landscape of the future&hellip; and, of course, the business plans at the center of it all.

And as for business plans, let's talk about one. By now you've probably heard of this "distributed media" business. If not, feel free to educate yourself <a href="http://www.niemanlab.org/2015/03/newsonomics-buzzfeed-and-the-new-york-times-play-facebooks-ubiquity-game/" target="_blank">here</a>. If you don't feel like a deep dive, the basic idea is this: Facebook is offering publishers the chance to "distribute" their stories natively on Facebook. So, rather than a thumbnail, title and abstract for a <em>New York Times</em> story showing up in a nice, little box in your newsfeed but linking back to NYTimes.com, you'll be able to read the whole thing, right there in Facebook. With the blue and the medium blue and the lighter blue and the Lucida Grande that you're used to. Plenty of people are aghast/annoyed/against this move, but let's be honest. Nobody is surprised. This is what happens when the desperate who shouldn't be desperate depend upon the less desperate who should be way more desperate. I know, I'm not a big Facebook fan &mdash; I've made that clear plenty &mdash; but I'll back that burn up eventually. But first, let me talk about how this is going to look awful and get that out of the way.

Because it is going to look awful. Granted, the publications who are most-named in this deal-with-the-desperate &mdash; <em>BuzzFeed</em> and <em>The New York Times</em> &mdash; are dipping their toes in to the stream first by *selectively* distributing their media via Facebook. Fine. But it's at least worth exploring what will happen when they get past this first-one's-free stage, get full-on addicted to attention stats, and send <em>all</em> their stuff elsewhere.&nbsp;So, what then? Will it be meaningful to talk about design direction at a publication like that? Will a publication even care about fostering a unique design sensibility anymore? Perhaps not. But that sounds awfully apocalyptic to me. On the one hand, I see it going that way because publications are in that prime low-self-esteem phase that makes them so ripe for a bender. But on the other hand, I have to believe that a significant portion of their audience cares about the aesthetic experience of consuming their media. <em>WIRED Magazine</em> looked amazing in the late-90s to early-2000s. But then they had a changing of the guard in creative direction, and honestly, that made a huge difference. It's never really come back from that. <em>WIRED UK</em> had a bit of a stretch after that doing some interesting things with design, but that didn't last either. And through those transitions, I went from buying both to buying neither. I am sure I'm not of the majority as far as that's concerned, but I'm also sure I'm not alone. So yes, that's a very subjective anecdote to back up my point that design matters, and if a publication is simply going to feed text and images into a design system they don't control, then a significant portion of their identity is lost in the process.

The other part of a publication's identity, of course, is its editorial voice. I am sure that <em>BuzzFeed</em> and <em>The New York Times</em> feel quite confident that hanging out at Facebook won't change them, but I suspect otherwise. Initially, sure, a <em>BuzzFeed</em> story in your Facebook feed will have it's uniquely breezy/snarky/glib Buzzvibe, but for how long? How many <em>BuzzFeed</em> pieces will be distributed through Facebook before someone at Facebook starts giving notes? Initially, it'll be a matter of "the data say ____" and some poor groveler at <em>BuzzFeed</em> saying yessir because they're grateful to get any peek behind the Facebook curtain. But that won't last. Someone will eventually realize that it's a big waste of time to conduct data-driven editorial meetings between these two organizations and they'll start making things much more efficient by just sending one-way directives. And what is <em>BuzzFeed</em> going to say? No? Hardly. But then what? What's left of <em>BuzzFeed</em>? (And really, I'm picking on them more here because I'm betting on them giving it up way faster than <em>The New York Times</em> does.) And does this matter? I think it does. A lot. The context is a part of the editorial magisteria, isn't it? Not just in terms of controlling surrounding stories, or stewarding a unified point of view, or courageously pioneering a new one despite a resistant public, or even wielding theme as a curatorial tool. Context is how a publication defines itself, by situating the entire organization and everything it produces within a particular landscape or sub-culture. What is *Mother Jones* without Democracy, liberalism, or (gasp!) workers' unions? What is *The New Yorker* without New York? *Cook's Illustrated* without gastronomy? Etc. Etc. Etc. Only Facebook will have the data to understand its landscape, and frankly, they probably can't be trusted to share or use that data unless it benefits them or strengthens their economic position. Remember, this is an organization &mdash; vast as it may be &mdash; still searching for a distinguishing business model. This is an organization in denial of the *fact* that it is an ad network. Once publications surrender their context then the vast, deep, and dark chasm of difference between and editor and a manager will shrink to another minor shade of difference, one that will push an editor from one job description to another. Or, in other words, it will tear the artistic jugular from the already pale, withering torso of the editorial body. I've seen this for myself. It's happening in so many publications already, even without Facebook's help. Two I've written for in the last few years have seen many editors come and go, all because they're treated (and expected to act) like production managers, nothing more. And those two &mdash; which will remain nameless &mdash; used to work nicely as compliments to one another, looking at an industry from different, but equally important vantage points. Now, after having been put through the ringer of experiments in shared resources, they hardly look or read differently at all. It's a shame.

Finally, economics. This is the problem underneath it all. The economics of attention. To get us in the mood, here's a <A href="http://digiday.com/publishers/publishers-approaching-snapchat-discover/" target="_blank">quote</a> from one publishing executive, who requested anonymity, extolling the virtues of distributing through Snapchat's new "Discover" feature:

> "I can't tell you what the numbers are, but they're fucking incredible."

I'll bet they are. I mean, otherwise, he would have just said "incredible," right? So how many combined seconds of attention are we talking about? A whole effing lot? Great. So *millions*. But how much attention for *one* user equals a user who wants to pay for something, or do something other than what you've already lured him to do? I'm willing to bet it's a&nbsp;lot more than that incredible&nbsp;Snapchat number. The logic, I think, goes like this: <em>CNN</em> gets to drop a story into Snapchat's swirling mess of ephemera and short attention spans. Great. So, there's a billion eyeballs in there. Then, *some* of them tap that story and head back to <em>CNN</em> to read it. Cool. <em>CNN</em> gets a flood of referral traffic, which makes Snapchat look great. But, then what? Does <em>CNN</em> get a ton of *deep* attention they can use to boost advertisers' confidence? Of course not! They get a skyrocketing bounce rate. Trending toward 100%, probably. So, then what? Not much! See, advertisers want attention. Real attention! The Glenngarry Attention! That leaves <em>CNN</em> and Snapchat little choice but to find a way to stuff an ad into the little <em>CNN</em> snippet that shows up in Snapchat's feed, where the attention starts. And that may not sound so bad &mdash; maybe it just says in small and unintrusive text, "This story sponsored by Starbucks" or whatever &mdash; but just wait until the advertisers want to be a little bit more front-and-center. I mean, think about it. This snippet we're talking about &mdash; is it not an ad itself? And now we're talking about stuffing another ad in there. Why would Snapchat allow that to happen? If Snapchat is selling attention to <em>CNN</em>, but then <em>CNN</em> realizes it's actually junk attention so they hit the board rooms to negotiate for more out of their "native" Snapchat experience, then Snapchat has to figure out some way to do that without alienating all its Snapchatters, who have been just *loving* the free Snapchat experience up until that point, but are now starting to get a little bummed out by all these ads, bro. Which is why any social&nbsp;platform &mdash; Snapchat, in this example, but really, all of them&nbsp;&mdash; hopes to god that the plebe-to-sponsored content ratio is *always* high on the plebe count. Which means that no matter what deals they make with publishers, nothing matters more than constant growth on the user side. And then keeping those users close. That's why social networks want these content deals. So that we stay. It's weird; no one really has great leverage here.

*Awl* writer Matt Buchanan <a href="http://www.theawl.com/2014/08/content-distributed" target="_blank">explains</a> it well:

> "Right now, '75 percent of BuzzFeed's traffic comes from referrals from social sites.' From a publisher's perspective, this is the ideal relationship between it and a 'social site': It plants a stick of dynamite (content) in a mountain (a social network in this dumb metaphor) and hopes it explodes, after which it can mine a precious commodity, eyeballs, which it transmutes into money. But the social sites view this relationship far differently: These 'referrals,' which send users to external sites, are not a resource to be harvested, but excreta, a waste byproduct made in the process of extracting users' attention on a weekly, daily, hourly basis. Efficiency demands that it is, in time, reduced to the minimum tolerable levels, if not outright eliminated."

Basically, publishers see value in the attention that overflows from social networks. So they think, let's get our content in there and harvest even more of it. But the social networks don't *really* want that. They want 100% attention efficiency. By letting publishers drop content into their streams, they hope to stop the attention leak &mdash; to *stop* users from leaving to go read things on other sites &mdash; the very thing the publishers hope will happen, even if some of it is consumed entirely in its "distributed" form. Who, in this scenario, should be paying who? Most stories about this movement in the industry suggest that the social networks are the buyers.

But Buchanan's *Awl* colleague (<em>The Awl</em> is awl over this subject)&nbsp;John Herman <a href="http://www.theawl.com/2015/03/the-terms-of-engagement" target="_blank">hits the nail on the head</a>:

> "If Facebook publishing is attractive to healthy companies, imagine how appealing it will be to dying ones."

For the terrified publishing industry, this must all seem like quite the miracle. On the level of someday-we'll-upload-our-consciousness-to-machines-and-live-forever singularity stuff. As in, wishful thinking. Because Facebook, et al, may be willing to sell this opportunity now, but certainly won't be forever. Herman goes on to put this see-saw in proper perspective:

> "Years of free referral traffic from Facebook have posed the question: When will Facebook want to keep this traffic for itself? Supposing years of future success&mdash;and putting out of mind that another law of platforms is eventual death&mdash;partner journalism poses its own version of this question: If Facebook knows what works, why outsource it?"

See, he's talking about plugging that attention leak there. With the biggest crowd,&nbsp;Facebook, especially,&nbsp;will quickly learn an awful lot about what "works," as in, what gets the most attention. And at that point, the big question *is* going to be, why outsource it? Or at least, why pay top-dollar to those shriveling, identityless media mercenaries on the East Coast when you could poach their best people, create your own embedded media divisions, and do the same thing from the big tent in California? Why, indeed.

So, again, who has the leverage? Content or platform? Facebook looks pretty strong in this analysis, but what about us? We're the reason Facebook is doing any of this. To keep us Facebooking. In the short term, so they can big-data us and pimp our stats to advertisers. In the long term, well, there aren't many ways out of that business model that don't involve risking going belly-up first, so instead, it seems like Facebook is going with an inflationary model. To expand what they are to the point that nobody leaves and, wham!, they're essentially their own interweb. Not a bad substitute for a lack of a meaningfully clear business model, is it? I mean, after all, *what is Facebook*? They say they're a "social network." A place to connect. OK, well, McDonald's could say that about themselves. But we know that's spin. McDonald's sells burgers; Facebook sells ads. Because they do this behind a smokescreen of here's-a-free-space-to-connect-and-enrich-your-lives, they're going to have a darn hard time directly selling us much of anything. You probably won't buy anything <em>from</em> Facebook, but give them enough time and latitude, and you'll probably buy something because of Facebook, or buy something within Facebook, or buy something through Facebook. If you stick around, that is.

It's a bit ironic, actually. This whole "distributed media" deal is also being called *Ubiquity*, as in, why limit your story to your publication, when it could be "everywhere?" But Facebook is the dealer. At least, the primary one. Facebook's idea of ubiquity isn't to increase the reach of any publication's media. Not really. It's to stretch the very idea of what Facebook is&nbsp;to the point that it's no longer anything in particular, but everything. And if all that cognitive surplus makes us even more enthusiastic consumers, then ubiquity stands to make Facebook a lot more money. It won't matter what you read or don't read, watch or don't watch, buy or don't buy. As long as you're on Facebook. Of course, we don't *have* to let this happen. We could just go someplace else.

But then, we'd have to be a whole lot less passive about this cognitive surplus business. And, we'd have to pay for what we consume, directly. I wonder, having been subsidized this long, can we afford that?

<p style="text-align:center;">♪</p>

**Heavy Rotation**: <a href="http://www.park.nl/park_cms/public/index.php?thisarticle=118" target="_blank">9 Beet Stretch</a>: Beethoven's 9th stretched to 24-hours. When I'm not listening to that, I'm <a href="http://listen.hatnote.com/" target="_blank">listening to Wikipedia</a>. Also, I've listened to this three times, so I guess that counts as heavy rotation: Remember that scene in <em>Indiana jones and the Last Crusade</em> when Indy and Elsa are exploring the catacombs beneath a library in Venice? Well, if you want to hear the real-life version of that, listen to the passage of <a href="http://www.cbc.ca/radio/ideas/underground-rome-1.2990465" target="_blank">this CBC Radio documentary</a> between 9:30 and 11:50 where an archaeologist and her guide explore underneath Rome. It's just as exciting as the Indy scene, if not more so.

<p style="text-align:center;">⎔</p>

**Recent Tabs**: <a href="http://laughterkey.com/post/113954583257" target="_blank">Please do not have an emergency at this location</a>. <a href="http://thenewinquiry.com/essays/the-future-bubble/" target="_blank">The Future Bubble</a>. The world's first <a href="http://theweek.com/speedreads/545014/take-many-selfies-want-worlds-first-selfie-museum" target="_blank">selfie museum</a>. So, the world can blow up now. Forget basketball. This bracket is <a href="http://jezebel.com/jezebels-march-madness-2015-internet-vs-irl-starts-no-1691894005" target="_blank">Internet v. IRL</a>. Photobomb level: <a href="http://40.media.tumblr.com/68e4f23f468d22c1996fe3e14e4bd1f4/tumblr_mhou3xz1Lw1ql2603o1_500.jpg" target="_blank">WHALE</a>. Is <a href="https://twitter.com/felixgilman/status/578581287356727296" target="=_blank">this</a> the worst sentence the English language is capable of generating? "<a href="https://www.youtube.com/watch?v=HDxgn-LS520" target="_blank">Are there cookies on this island?</a>" Be free. Be <a href="http://www.reactiongifs.com/r/yxd.gif" target="_blank">this guy</a>. For type nerds: <a href="http://creativereview.co.uk/cr-blog/2015/march/albertus-and-the-prisoner" target="_blank">Albertus and *The Prisoner*</a>. <a href="https://www.youtube.com/watch?v=36ffV-CI3Mo" target="_blank">The winds of Titan</a> as recorded by the Huygens Probe. This is its own form of time travel: <a href="http://kernelmag.dailydot.com/issue-sections/features-issue-sections/12228/mac-plus-modern-web/" target="_blank">Plugging a 1986 Mac Plus into the modern Web</a>. <a href="http://www.dailydot.com/geek/mark-millar-sean-murphy-chrononauts-optical-illusion/" target="_blank">This</a> is a more interesting optical illusion than The Dress.